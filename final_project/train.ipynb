{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77870127",
   "metadata": {},
   "source": [
    "### WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40342a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot style from IKT215, dpi set to 200\n",
    "def set_mpl_params(dpi: int = 200, figsize: Tuple[int, int] = (9, 6), grid: bool = True, font_size: int = 12, font_family: str = 'serif') -> None:\n",
    "    mpl.rcParams['figure.dpi'] = dpi\n",
    "    mpl.rcParams['figure.figsize'] = figsize\n",
    "    mpl.rcParams['axes.grid'] = grid\n",
    "    mpl.rcParams.update({'font.size': font_size})\n",
    "    mpl.rcParams['font.family'] = font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8922e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = \"meta-llama/Llama-3.2-1B\"\n",
    "    dataset_name: str = \"yahma/alpaca-cleaned\"\n",
    "    train_size: int = 10000\n",
    "    val_size: int = 2000\n",
    "    test_size: int = 2000\n",
    "    batch_size: int = 4\n",
    "    grad_accum_steps: int = 4\n",
    "    epochs: int = 3\n",
    "    lr: float = 0.0002\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.1\n",
    "    seed: int = 42\n",
    "    lora_rank: int = 8\n",
    "    lora_alpha: int = 16\n",
    "    lora_dropout: float = 0.05\n",
    "    output_dir: Path = Path(\"outputs/checkpoints\")\n",
    "    max_length: int = 512\n",
    "    use_fp16: bool = True\n",
    "    report_to: Optional[str] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecdd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "seed_everything(cfg.seed)\n",
    "set_mpl_params()\n",
    "cfg.output_dir.mkdir(parents = True, exist_ok = True)\n",
    "cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
