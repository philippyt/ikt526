{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e800c4f2-1a29-4b72-9596-cb62b2adf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f5c1ed-b614-4f3f-9ebf-50d2b80f736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:40:43.895851: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, math, random\n",
    "import numpy as np, pandas as pd, matplotlib as mpl, matplotlib.pyplot as plt, seaborn as sns\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, List\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cf19d4-66fb-4455-84b6-905f884403cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot style from IKT215, dpi set to 200\n",
    "def set_mpl_params(dpi: int = 200, figsize: Tuple[int, int] = (9, 6), grid: bool = True, font_size: int = 12, font_family: str = 'serif') -> None:\n",
    "    mpl.rcParams['figure.dpi'] = dpi\n",
    "    mpl.rcParams['figure.figsize'] = figsize\n",
    "    mpl.rcParams['axes.grid'] = grid\n",
    "    mpl.rcParams.update({'font.size': font_size})\n",
    "    mpl.rcParams['font.family'] = font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db018c3b-2a1b-4b48-8ff0-adb623c4bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducilbity\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e635001-3aa6-4f6e-a699-6fc7ef15fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams given in the assignment text, dataclass decorator used for cleaner setup\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = \"distilbert-base-uncased\"\n",
    "    batch_size: int = 16\n",
    "    grad_accum_steps: int = 2\n",
    "    epochs: int = 10\n",
    "    lr: float = 0.00002\n",
    "    weight_decay: float = 0.01\n",
    "    max_len: int = 512\n",
    "    val_split: float = 0.2\n",
    "    seed: int = 42\n",
    "    warmup_ratio: float = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9368680b-fcd9-4bc9-9a7d-ef07908d5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "set_mpl_params()\n",
    "seed_everything(cfg.seed)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db325b7-2ef2-43f4-ab37-6be6093dfe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f79da0-cbd7-4e5a-8a13-6485d0944398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"dataset.parquet\")\n",
    "assert {\"title\", \"content\", \"label\"}.issubset(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad54047e-90c3-498a-9ec8-e9e1bac24f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"label\"])\n",
    "# converting np.int64 in dicts to plain python types due to issues with data type handling\n",
    "# str(lbl) makes it so json can serialize labels, and int(i) makes it so the ids are int instead\n",
    "label2id = {str(lbl): int(i) for lbl, i in zip(le.classes_, range(len(le.classes_)))}\n",
    "id2label = {int(i): str(lbl) for lbl, i in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7b16c5-1844-4737-9cfa-303141f8ca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 84000, validation size: 28000, test size: 28000\n"
     ]
    }
   ],
   "source": [
    "# split into train, validation, and test (0.6 / 0.2 / 0.2)\n",
    "train_df, temp_df = train_test_split(df, test_size = 0.4, stratify = df[\"label_id\"], random_state = cfg.seed)\n",
    "val_df, test_df = train_test_split(temp_df, test_size = 0.5, stratify = temp_df[\"label_id\"], random_state = cfg.seed)\n",
    "print(f\"train size: {len(train_df)}, validation size: {len(val_df)}, test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8686583-c787-4c90-bff2-382644c98b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label distribution in full dataset:\n",
      "label\n",
      "4     0.071\n",
      "13    0.071\n",
      "5     0.071\n",
      "9     0.071\n",
      "2     0.071\n",
      "7     0.071\n",
      "0     0.071\n",
      "12    0.071\n",
      "3     0.071\n",
      "6     0.071\n",
      "8     0.071\n",
      "10    0.071\n",
      "11    0.071\n",
      "1     0.071\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "label distribution in splits:\n",
      "train: label\n",
      "1     0.071\n",
      "6     0.071\n",
      "3     0.071\n",
      "12    0.071\n",
      "11    0.071\n",
      "13    0.071\n",
      "5     0.071\n",
      "8     0.071\n",
      "2     0.071\n",
      "9     0.071\n",
      "4     0.071\n",
      "7     0.071\n",
      "10    0.071\n",
      "0     0.071\n",
      "Name: proportion, dtype: float64\n",
      "val:   label\n",
      "12    0.071\n",
      "9     0.071\n",
      "8     0.071\n",
      "10    0.071\n",
      "0     0.071\n",
      "4     0.071\n",
      "6     0.071\n",
      "11    0.071\n",
      "5     0.071\n",
      "3     0.071\n",
      "13    0.071\n",
      "1     0.071\n",
      "2     0.071\n",
      "7     0.071\n",
      "Name: proportion, dtype: float64\n",
      "test:  label\n",
      "8     0.071\n",
      "4     0.071\n",
      "7     0.071\n",
      "6     0.071\n",
      "2     0.071\n",
      "1     0.071\n",
      "0     0.071\n",
      "5     0.071\n",
      "12    0.071\n",
      "13    0.071\n",
      "10    0.071\n",
      "9     0.071\n",
      "3     0.071\n",
      "11    0.071\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# verify label distribution consistency\n",
    "print(\"\\nlabel distribution in full dataset:\")\n",
    "print(df['label'].value_counts(normalize = True).round(3))\n",
    "\n",
    "print(\"\\nlabel distribution in splits:\")\n",
    "print(\"train:\", train_df['label'].value_counts(normalize = True).round(3).head(14))\n",
    "print(\"val:  \", val_df['label'].value_counts(normalize = True).round(3).head(14))\n",
    "print(\"test: \", test_df['label'].value_counts(normalize = True).round(3).head(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274456a2-d0bd-4414-9781-fecfd8470bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBpediaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: DistilBertTokenizer, max_length: int = 512):\n",
    "        # combine title and content into a single text input\n",
    "        # title provides context and content has the detail, joining both improves the coverage\n",
    "        # \"[SEP]\" added to help the model distinguish sections\n",
    "        self.texts = [f\"title: {t} [SEP] content: {c}\" for t, c in zip(df[\"title\"], df[\"content\"])]\n",
    "        self.labels = df[\"label_id\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        text = str(self.texts[idx]) if self.texts[idx] is not None else \"\"\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, padding = \"max_length\", truncation = True, max_length = self.max_length, return_tensors = \"pt\")\n",
    "        return {\"input_ids\": encoding[\"input_ids\"].squeeze(0), \"attention_mask\": encoding[\"attention_mask\"].squeeze(0), \"labels\": torch.tensor(label, dtype = torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe8b70b-9a04-455e-a9d3-49d590551bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ffb28ed-a23e-43dc-a5ca-b82cec7b99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DBpediaDataset(train_df, tokenizer, cfg.max_len)\n",
    "val_ds = DBpediaDataset(val_df, tokenizer, cfg.max_len)\n",
    "test_ds = DBpediaDataset(test_df, tokenizer, cfg.max_len)\n",
    "train_loader = DataLoader(train_ds, batch_size = cfg.batch_size, shuffle = True, num_workers = 2, pin_memory = torch.cuda.is_available())\n",
    "val_loader = DataLoader(val_ds, batch_size = cfg.batch_size, shuffle = False, num_workers = 2, pin_memory = torch.cuda.is_available())\n",
    "test_loader = DataLoader(test_ds, batch_size = cfg.batch_size, shuffle = False, num_workers = 2, pin_memory = torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25443a1c-0800-41c9-ac0e-bd02a76e6d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([16, 512])\n",
      "attention_mask shape: torch.Size([16, 512])\n",
      "labels shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# verify tokenized tensor shapes\n",
    "sample = next(iter(train_loader))\n",
    "print(f\"input_ids shape: {sample['input_ids'].shape}\")\n",
    "print(f\"attention_mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"labels shape: {sample['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "046914a5-3ca5-45fd-b070-54d1f94d9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(cfg.model_name, num_labels = 14, id2label = id2label, label2id = label2id).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9d67ba-2f93-47ca-8bb5-85ce00669f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "109f3d36-5275-45c9-a280-780da4a2c7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 6, 'hidden_size': 768, 'ffn_dim': 3072, 'activation': 'gelu', 'n_heads': 12}\n"
     ]
    }
   ],
   "source": [
    "print({\"n_layers\": model_config.n_layers, \"hidden_size\": model_config.dim, \"ffn_dim\": model_config.hidden_dim, \"activation\": model_config.activation, \"n_heads\": model_config.n_heads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d769b5a-4a81-4473-b563-49e065ba2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_weights(model: DistilBertForSequenceClassification, tokenizer: DistilBertTokenizer, text: str, layer_idx: int = 5) -> Tuple[np.ndarray, List[str]]:\n",
    "    inputs = tokenizer(text, return_tensors = 'pt', truncation = True, padding = True, max_length = 512).to(DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.base_model(**inputs, output_attentions=True)\n",
    "    attentions = outputs.attentions\n",
    "    layer_attention = attentions[layer_idx][0].detach().cpu().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu())\n",
    "    return layer_attention, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da38dff-bd75-4125-aa28-eda62c715a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_heatmap(attn: np.ndarray, tokens: List[str], title: str, path: str) -> None:\n",
    "    set_mpl_params()\n",
    "    plt.figure(dpi=200)\n",
    "    plt.imshow(attn, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
    "    plt.yticks(range(len(tokens)), tokens)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71431ccc-d558-40d5-ac80-93f0c870f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"A robot may not injure a human being or, through inaction, allow a human being to come to harm.\"\n",
    "# get middle transformer block and one-third into the head set (to avoid extremes)\n",
    "LAYER, HEAD = model.config.n_layers // 2, model.config.n_heads // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe247e3-1fff-4c66-8b77-7af2385c60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "pre_attn, pre_tokens = get_attention_weights(model, tokenizer, sentence, LAYER)\n",
    "plot_attention_heatmap(pre_attn[HEAD], pre_tokens, f\"Pre-training layer {LAYER}, head {HEAD}\", \"graphs/attn_pre_single.png\")\n",
    "plot_attention_heatmap(pre_attn.mean(axis=0), pre_tokens, f\"Pre-training layer {LAYER} (Average heads)\", \"graphs/attn_pre_avg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87385cbd-4bae-4bc6-a716-4f259e32541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lengths = [len(tokenizer.encode(f\"title: {t} [SEP] content: {c}\", truncation=False)) for t, c in zip(df[\"title\"].head(2000), df[\"content\"].head(2000))]\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.hist(raw_lengths, bins=40, alpha=0.8)\n",
    "plt.axvline(512, linestyle='--', linewidth=1.5, label='max length (512)')\n",
    "plt.title(\"Distribution of raw tokenized sequence lengths (first 2000 samples)\")\n",
    "plt.xlabel(\"Sequence length (tokens)\"); plt.ylabel(\"count\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"graphs/token_length_distribution.png\", dpi=200); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b3f700e-1f2a-48b5-b51f-85b1d01136d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = cfg.lr, weight_decay = cfg.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4ebca7-57af-4dfb-90e9-db65c426dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting hyperparams from config to calculate total steps and warmup steps\n",
    "steps_per_epoch = math.ceil(len(train_ds) / cfg.batch_size)\n",
    "optimizer_steps_per_epoch = math.ceil(steps_per_epoch / cfg.grad_accum_steps)\n",
    "total_steps = optimizer_steps_per_epoch * cfg.epochs\n",
    "warmup_steps = int(cfg.warmup_ratio * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e46902d-788e-41c2-9898-f4cc9facd4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 26250, Warmup steps: 2625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total steps: {total_steps}, Warmup steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe239a0-392c-468c-80de-7a6b449b221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: DistilBertForSequenceClassification, dataloader: DataLoader, optimizer: torch.optim.Optimizer, scheduler: torch.optim.lr_scheduler.LambdaLR, device: torch.device, grad_accum_steps=cfg.grad_accum_steps) -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    progress_bar = tqdm(total = len(dataloader), desc = \"Training\", leave = False)\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
    "        loss = outputs.loss / grad_accum_steps\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * grad_accum_steps\n",
    "        if (step + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none = True)\n",
    "        if (step + 1) % 500 == 0 or (step + 1) == len(dataloader):\n",
    "            progress_bar.update(500 if (step + 1) % 500 == 0 else len(dataloader) % 500)\n",
    "            progress_bar.set_postfix({\"loss\": f\"{loss.item() * grad_accum_steps:.4f}\"})\n",
    "    progress_bar.close()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d51cf544-916a-4d97-b133-ab1152b84b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: DistilBertForSequenceClassification, dataloader: DataLoader, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    preds, labels_list = [], []\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "            preds.extend(outputs.logits.argmax(dim = 1).cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(labels_list, preds)\n",
    "    return acc, total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a85dcba-2051-4cb7-826f-58b047939928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918281abae3c4cf2a11681f30fa273ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/5250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "train_losses, val_losses, val_accs = [], [], []\n",
    "\n",
    "epoch_bar = tqdm(range(1, cfg.epochs + 1), desc=\"Training epochs\")\n",
    "for epoch in epoch_bar:\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, DEVICE, cfg.grad_accum_steps)\n",
    "    val_acc, val_loss = evaluate(model, val_loader, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    epoch_bar.set_postfix({\"train_loss\": f\"{train_loss:.4f}\", \"val_loss\": f\"{val_loss:.4f}\", \"val_acc\": f\"{val_acc:.4f}\"})\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        tqdm.write(\"Saved best_model.pt\")\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88b802c2-a3ec-44f3-b33f-f37488602903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "best_model = DistilBertForSequenceClassification.from_pretrained(cfg.model_name, num_labels =14, id2label = id2label, label2id = label2id).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pt\", map_location = DEVICE))\n",
    "post_attn, post_tokens = get_attention_weights(best_model, tokenizer, sentence, LAYER)\n",
    "plot_attention_heatmap(post_attn[HEAD], post_tokens, f\"Post-training layer {LAYER}, head {HEAD}\", \"graphs/attn_post_single.png\")\n",
    "plot_attention_heatmap(post_attn.mean(axis=0), post_tokens, f\"Post-training layer {LAYER} (Average heads)\", \"graphs/attn_post_avg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91cb2d0a-cca6-477a-9233-d54656e978e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 200)\n",
    "plt.plot(train_losses, label = \"Training loss\")\n",
    "plt.plot(val_losses, label = \"Validation loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"graphs/loss_curve.png\", dpi = 200); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e31def2f-a216-496a-bdfd-1331fc6b5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 200)\n",
    "plt.plot(val_accs, label = \"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"graphs/accuracy_curve.png\", dpi = 200); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f006b0a-100b-4d86-808c-5ec57583d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f949586-47d8-4e99-92b5-041c81200250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "testing:   0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc = \"testing\", leave = False):\n",
    "        ids, mask, labels = batch[\"input_ids\"].to(DEVICE), batch[\"attention_mask\"].to(DEVICE), batch[\"labels\"].to(DEVICE)\n",
    "        outputs = best_model(input_ids = ids, attention_mask = mask)\n",
    "        preds = outputs.logits.argmax(dim = 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f381f49d-d61c-4c1b-b616-f79bdd52436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average = None, zero_division = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "313941c3-21b2-4351-a5ce-2aea2195948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize = (9, 7), dpi = 200)\n",
    "sns.heatmap(cm, annot = True, fmt = \"d\", cmap = \"Blues_r\", xticklabels = id2label.values(), yticklabels = id2label.values(), cbar = False, linewidths = 0.4, linecolor = \"gray\")\n",
    "plt.title(\"Confusion matrix - test set\", pad = 12)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(rotation = 45, ha = \"right\", fontsize = 8)\n",
    "plt.yticks(rotation = 0, fontsize = 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/confusion_matrix_test.png\", dpi = 200, bbox_inches = \"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ed0fc9d-1ae0-4ef4-91ce-bb5c5a812f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\", \"MeanOfTransportation\", \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\", \"Album\", \"Film\", \"WrittenWork\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe7902c3-c111-4ebe-ad73-b2d6ba5efb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision = np.mean(precision)\n",
    "avg_recall = np.mean(recall)\n",
    "avg_f1 = np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eddb492e-87db-4cb0-9cae-4dbd9cdb66f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-class performance metrics\n",
      "---------------------------------------------------------------------------\n",
      "Class                       Precision      Recall    F1 Score\n",
      "---------------------------------------------------------------------------\n",
      "Company                        0.9653      0.9740      0.9696\n",
      "EducationalInstitution         0.9949      0.9795      0.9872\n",
      "Artist                         0.9879      0.9805      0.9842\n",
      "Athlete                        0.9970      0.9975      0.9973\n",
      "OfficeHolder                   0.9830      0.9850      0.9840\n",
      "MeanOfTransportation           0.9935      0.9925      0.9930\n",
      "Building                       0.9728      0.9825      0.9776\n",
      "NaturalPlace                   0.9950      0.9970      0.9960\n",
      "Village                        0.9985      0.9990      0.9988\n",
      "Animal                         0.9965      0.9960      0.9962\n",
      "Plant                          0.9955      0.9945      0.9950\n",
      "Album                          0.9930      0.9970      0.9950\n",
      "Film                           0.9960      0.9950      0.9955\n",
      "WrittenWork                    0.9960      0.9945      0.9952\n",
      "---------------------------------------------------------------------------\n",
      "Macro average                  0.9904      0.9903      0.9903\n",
      "Overall cccuracy:              0.9903\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPer-class performance metrics\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Class':<25}{'Precision':>12}{'Recall':>12}{'F1 Score':>12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for c, p, r, f in zip(classes, precision, recall, f1):\n",
    "    print(f\"{c:<25}{p:>12.4f}{r:>12.4f}{f:>12.4f}\")\n",
    "\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Macro average':<25}{avg_precision:>12.4f}{avg_recall:>12.4f}{avg_f1:>12.4f}\")\n",
    "print(f\"{'Overall cccuracy:':<25}{acc:>12.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
